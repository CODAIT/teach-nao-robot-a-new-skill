<?xml version="1.0" encoding="UTF-8" ?>
<ChoregrapheProject xmlns="http://www.aldebaran-robotics.com/schema/choregraphe/project.xsd" xar_version="3">
    <Box name="root" id="-1" localization="8" tooltip="Root box of Choregraphe&apos;s behavior. Highest level possible." x="0" y="0">
        <bitmap>media/images/box/root.png</bitmap>
        <script language="4">
            <content>
                <![CDATA[]]>
</content>
        </script>
        <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
        <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
        <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
        <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
        <Timeline enable="0">
            <BehaviorLayer name="behavior_layer1">
                <BehaviorKeyframe name="keyframe1" index="1">
                    <Diagram>
                        <Box name="environment_setup" id="2" localization="8" tooltip="" x="96" y="74">
                            <bitmap>media/images/box/box-python-script.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[# ---------------------------------
# define globals
# ---------------------------------
# TODO: customize ip address and port number
resnet_ip_port = '169.254.152.166:6050'
# standard prediction endpoint URL for models from the Exchange is /model/predict
resnet_inference_url = 'http://{}/model/predict'.format(resnet_ip_port)

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_onStart(self):
        self.onStopped() #activate the output of the box
        pass

    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                        </Box>
                        <Box name="Select Camera" id="4" localization="8" tooltip="Change the currently used camera." x="250" y="80">
                            <bitmap>media/images/box/interaction/look.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.kCameraSelectID = 18
        self.cameraModule = ALProxy( "ALVideoDevice" )

    def onLoad(self):
        pass

    def onUnload(self):
        pass

    def onInput_onUseTopCamera(self):
        self.cameraModule.setParam( self.kCameraSelectID, 0 )
        self.onReady()

    def onInput_onUseBottomCamera(self):
        self.cameraModule.setParam( self.kCameraSelectID, 1 )
        self.onReady()]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onUseTopCamera" type="1" type_size="1" nature="1" inner="0" tooltip="Use the camera at the top of the head (forehead)." id="2" />
                            <Input name="onUseBottomCamera" type="1" type_size="1" nature="1" inner="0" tooltip="Use the camera at the bottom of the head (mouth)." id="3" />
                            <Output name="onReady" type="1" type_size="1" nature="2" inner="0" tooltip="The camera change is done." id="4" />
                            <Resource name="Camera setting" type="Lock" timeout="0" />
                        </Box>
                        <Box name="Take Picture" id="5" localization="8" tooltip="Take a picture with one of the cameras camera and store it in his memory in ~/recordings/cameras. The image format is JPG.&#x0A;&#x0A;V1.1.0&#x0A;" x="385" y="77">
                            <bitmap>media/images/box/interaction/picture.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import os
import time

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self, False)
        self.resolutionMap = {
            '160 x 120': 0,
            '320 x 240': 1,
            '640 x 480': 2,
            '1280 x 960': 3
        }
        self.cameraMap = {
            'Top': 0,
            'Bottom': 1
        }

        self.recordFolder = "/home/nao/recordings/cameras/"

    def onLoad(self):
        self.bIsRunning = False
        try:
            self.photoCapture = ALProxy( "ALPhotoCapture" )
        except Exception as e:
            self.photoCapture = None
            self.logger.error(e)

    def onUnload(self):
        pass

    def onInput_onStart(self):
        if( self.bIsRunning ):
            return
        self.bIsRunning = True
        resolution = self.resolutionMap[self.getParameter("Resolution")]
        cameraID = self.cameraMap[self.getParameter("Camera")]
        fileName = self.getParameter("File Name")
        if self.photoCapture:
            self.photoCapture.setResolution(resolution)
            self.photoCapture.setCameraID(cameraID)
            self.photoCapture.setPictureFormat("jpg")
            self.photoCapture.takePicture( self.recordFolder, fileName )
            image = os.path.join(self.recordFolder, fileName)
            self.log('Photo was saved in {}'.format(image))
        self.bIsRunning = False
        self.marvinViewPicture(image)]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="onStart" type="1" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Output name="marvinViewPicture" type="3" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="3" />
                            <Parameter name="Resolution" inherits_from_parent="0" content_type="3" value="640 x 480" default_value="640 x 480" custom_choice="0" tooltip="Image resolution." id="4">
                                <Choice value="160 x 120" />
                                <Choice value="320 x 240" />
                                <Choice value="640 x 480" />
                                <Choice value="1280 x 960" />
                            </Parameter>
                            <Parameter name="File Name" inherits_from_parent="0" content_type="3" value="marvin_view.jpg" default_value="image" custom_choice="0" tooltip="Name of the file without its extension." id="5" />
                            <Parameter name="Camera" inherits_from_parent="0" content_type="3" value="Top" default_value="Top" custom_choice="0" tooltip="Enables to select the camera (Top or Bottom) that will take the picture." id="6">
                                <Choice value="Top" />
                                <Choice value="Bottom" />
                            </Parameter>
                        </Box>
                        <Box name="analyze_view" id="6" localization="8" tooltip="" x="530" y="77">
                            <bitmap>media/images/box/box-python-script.png</bitmap>
                            <script language="4">
                                <content>
                                    <![CDATA[import json
import requests

class MyClass(GeneratedClass):
    def __init__(self):
        GeneratedClass.__init__(self)
        self.tts = ALProxy('ALTextToSpeech')

    def onLoad(self):
        #put initialization code here
        pass

    def onUnload(self):
        #put clean-up code here
        pass

    def onInput_picture(self, p):
        '''
        Identify objects in an image by calling an external microservice
        Input: location of an image that was taken using the camera
        '''
        self.log('Image location is {}'.format(p))
        with open(p) as f:
         # formdata payload: the captured image
         files = {'image' : f}
         print('Sending inference request to {} ...'.format(resnet_inference_url))
         # send a POST request to the service's /model/predict endpoint
         r = requests.post(resnet_inference_url, files = files)

         if r.status_code > 200:
           self.logger.error('Inference request returned HTTP code {} and message {}'.format(r.status_code, r.text))
         else:
           # HTTP 200 response returns JSON; parse and extract 'predictions' array
           objects = r.json()['predictions']
           if len(objects) == 0:
              # ... no objects could be identified
              # sad response, e.g.
              self.tts.say('I saw something but I don\'t know what it is.')
           else:
              for object in objects:
                # label: identifies the object type
                # probability: quantifies the confidence [0...1], 1 = highest confidence
                self.log('Object: {} probability: {}'.format(object['label'], object['probability']))
                if object['probability'] > 0.05:
                  self.tts.say('I see a {}'.format(object['label']))
                else:
                  self.tts.say('I think there is a {}? '.format(object['label']))
        #self.onStopped() #activate the output of the box

    def onInput_onStop(self):
        self.onUnload() #it is recommended to reuse the clean-up as the box is stopped
        self.onStopped() #activate the output of the box]]>
</content>
                            </script>
                            <Input name="onLoad" type="1" type_size="1" nature="0" inner="1" tooltip="Signal sent when diagram is loaded." id="1" />
                            <Input name="picture" type="3" type_size="1" nature="2" inner="0" tooltip="Box behavior starts when a signal is received on this input." id="2" />
                            <Input name="onStop" type="1" type_size="1" nature="3" inner="0" tooltip="Box behavior stops when a signal is received on this input." id="3" />
                            <Output name="onStopped" type="1" type_size="1" nature="1" inner="0" tooltip="Signal sent when box behavior is finished." id="4" />
                        </Box>
                        <Link inputowner="2" indexofinput="2" outputowner="0" indexofoutput="2" />
                        <Link inputowner="5" indexofinput="2" outputowner="4" indexofoutput="4" />
                        <Link inputowner="6" indexofinput="2" outputowner="5" indexofoutput="3" />
                        <Link inputowner="4" indexofinput="2" outputowner="2" indexofoutput="4" />
                    </Diagram>
                </BehaviorKeyframe>
            </BehaviorLayer>
        </Timeline>
    </Box>
</ChoregrapheProject>
